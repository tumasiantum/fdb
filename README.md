# Foundation db report
## Общие описание
FoundationDB — это распределенная NoSQL база данных с ACID-транзакциями уровня Serializable, хранящая отсортированные пары ключ-значение (ordered key-value store). Ключами и значениями могут быть произвольные последовательности байт. У неё нет единой точки падения — все машины кластера равноправны. Она сама распределяет данные по серверам кластера и  масштабируется на лету: когда в кластер нужно добавить ресурсов, ты просто добавляешь адрес новой машины на конфигурационных серверах и база сама подхватывает ее.

## История
FoundationDB написана на C++. Работу над ней авторы начали в 2009 году, первая версия была выпущена в 2013-м, а в марте 2015-го их купила корпорация Apple. Спустя три года Apple неожиданно открыла исходный код. Ходят слухи, что Apple использует ее, среди прочего, для хранения данных сервиса iCloud.

FoundationDB Alpha появилась в январе 2012 года и прекратила свое существование 4 марта 2013 года публичным бета-релизом. Эта версия 1.0 была выпущена в качестве общедоступной 20 августа 2013 года.

25 марта 2015 года сообщалось, что Apple приобрела компанию.

## Принцип установки
Серверы и клиенты FoundationDB используют файл кластера (обычно с именем fdb.cluster) для подключения к кластеру. Содержимое файла кластера одинаково для всех процессов, подключающихся к кластеру. Файл fdb.cluster создается автоматически при установке сервера FoundationDB и автоматически обновляется при смене серверов координации.

## Python API
FoundationDB Python API совместим с Python 2.7 - 3.7. Вам необходимо иметь версию Python в пределах этого диапазона в вашей системе, прежде чем можно будет установить FoundationDB Python API. Также есть поддержка других языков (Java, Moosh, Ruby, Go...)

## Чтение и запись
В FoundationDB транзакции никогда не блокируют друг друга. Чтение реализовано через мультиверсионный контроль версий (MVCC), а запись — через оптимистичный контроль параллелизма (OCC). Разработчики заявляют, что когда все машины кластера в одном дата-центре, то задержка на запись данных (write latency) составляет 2-3 мс, а на чтение (read latency) — меньше миллисекунды. В документации встречаются оценки в 10-15 мс, что, вероятно, ближе к результатам в реальных условиях.

## Архитектура

Логически кластер FoundationDB представляет собой набор однотипных процессов на разных физических машинах. У процессов нет собственных конфигурационных файлов, поэтому они взаимозаменяемы. Несколько фиксированных процессов имеют выделенную роль — Coordinators, и каждый процесс кластера при старте знает их адреса. Важно, чтобы падения Coordinators были максимально независимыми, поэтому их лучше размещать на разных физических машинах или даже в разных дата-центрах.

Coordinators договариваются между собой через консенсус-алгоритм Paxos. Они выбирают процесс Cluster Controller, который дальше назначает роли остальным процессам кластера. Cluster Controller непрерывно сообщает всем Coordinators, что он жив. Если большинство Coordinators считает, что он умер, они просто выбирают нового. Ни Cluster Controller, ни Coordinators не участвуют в обработке транзакций, их главная задача — исключить ситуацию split brain.

Когда клиент хочет подключиться к БД, он обращается сразу ко всем Coordinators за адресом текущего Cluster Controller. Если большинство ответов совпало, он получает из Cluster Controller полную текущую конфигурацию кластера (если не совпало — обращается к Coordinators повторно).

## Обработка запросов

Все клиентские запросы обрабатывают процессы Proxy. Открывая транзакцию, клиент обращается к любому Proxy, тот опрашивает все остальные Proxy, и возвращает текущий номер версии данных кластера. Все последующие чтения происходят по этому номеру версии. Если другой клиент записал данные после того, как я открыл транзакцию, я его изменения просто не увижу.

Запись транзакции немного сложнее, поскольку нужно разруливать конфликты. Здесь включается процесс Resolver, который хранит в памяти все модифицированные ключи за некоторый период времени. Когда клиент завершает (commit) транзакцию записи, Resolver проверяет, не устарели ли данные, которые она читала. (То есть не было ли завершено транзакции, которая была открыта позже моей и изменила ключи, которые я читал.) Если такое произошло, транзакцию откатывают и клиентская библиотека сама(!) делает повторную попытку коммита. Единственное, о чём должен думать разработчик, — это чтобы транзакции были идемпотентные, то есть повторное применение должно давать идентичный результат. Один из способов добиться этого — сохранять в рамках транзакции какое-то уникальное значение, а в начале транзакции проверять его наличие в базе.

## Масштабирование

В подсистеме хранения данных (Storage) могут быть тысячи серверов. К какому из них клиент должен обратиться, когда нужны данные по определенному ключу? От Cluster Controller клиент знает полную конфигурацию всего кластера, а она включает диапазоны ключей на каждом Storage-сервере. Поэтому он просто обращается напрямую к нужным Storage-серверам без каких-либо промежуточных запросов. 

Если нужный Storage-сервер недоступен, то клиентская библиотека берет у Cluster Controller новую конфигурацию. Если в результате падения сервера кластер понимает, что избыточность недостаточна, он сразу же начинает собирать новую ноду из кусочков других Storage. 

##Ограничения

Помимо уже упомянутых пределов на размеры и длину транзакции, важно отметить следующие особенности: 

1. Язык запросов — не SQL, то есть разработчикам с опытом SQL придется переучиваться.
1. Клиентская библиотека поддерживает только 5 высокоуровневых языков (Phyton, Ruby, Java, Golang и C). Пока нет официального клиента для C#. Поскольку нет REST API, то единственный способ поддержать другой язык — это написать на нем обертку поверх стандартной библиотеки на C.
1. Нет механизмов разделения доступа, всю эту логику должно обеспечивать ваше приложение.
1. Не документирован формат хранения данных (хотя в коммерческих базах данных он тоже обычно не документируется). Это риск, потому что если вдруг кластер не соберется, то сходу непонятно, что делать и придется копаться в исходных файлах.
1. Строго асинхронная модель программирования может казаться сложной начинающим разработчикам.
1. Нужно постоянно думать об идемпотентности транзакций.
1. Если придется разбивать длинные транзакции на маленькие, то о целостности на глобальном уровне нужно заботиться самому.

## Перспективы

В разработке ПО есть такой экзистенциальный конфликт: бизнес постоянно хочет от продукта изменений, улучшений. Но при этом хочет надежный софт. А эти два требования противоречат друг другу, потому что когда софт меняется, появляются баги и бизнес от этого страдает. Поэтому если в вашем продукте вы можете опереться на какую-то надежную, проверенную технологию и меньше кода писать самому, это всегда стоит сделать. В этом смысле, невзирая на определенные ограничения, круто иметь возможность не лепить костыли к разным NoSQL-базам данных, а использовать проверенное в продакшене решение с ACID-свойствами.

## Пример (отдельный файл)

Допустим, нас попросили создать систему планирования занятий для учащихся и администраторов. Мы пройдемся по разработке и внедрению этого приложения.

## Общее впечатление

[Документация (англ)](https://apple.github.io/foundationdb/index.html) производит впечатление не обновляемой, актуальной версиии на сайте нет, только GIT. Обучающих источников/курсов нет вообще, искал на русском и английском. Сложилось впечатление очень "ОТКРЫТОГО" софта.
